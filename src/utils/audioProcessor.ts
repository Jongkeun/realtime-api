// ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìƒìˆ˜ë“¤
const INPUT_TARGET_SR = 16000; // OpenAI Realtime ì…ë ¥ ê¶Œì¥ (PCM16)
const OUTPUT_SAMPLE_RATE = 24000; // OpenAI Realtime ì¶œë ¥(PCM16) ê¸°ë³¸
const BUFFER_SIZE = 4096;
const CHANNELS = 1; // ëª¨ë…¸

export class AudioProcessor {
  private audioContext: AudioContext | null = null;

  // ì…ë ¥(ê²ŒìŠ¤íŠ¸ ë§ˆì´í¬ or ì›ê²© ìŠ¤íŠ¸ë¦¼) ì²˜ë¦¬ìš©
  private sourceNode: MediaStreamAudioSourceNode | null = null;
  private processorNode: ScriptProcessorNode | null = null;

  // ì¶œë ¥(ê²ŒìŠ¤íŠ¸ë¡œ ë³´ë‚¼ AI ìŒì„±) ì²˜ë¦¬ìš©
  private streamDestination: MediaStreamAudioDestinationNode | null = null;
  private aiResponseStream: MediaStream | null = null;

  // (ì„ íƒ) ë¡œì»¬ ì¬ìƒ/ë³¼ë¥¨ ì¡°ì ˆìš©
  private gainNode: GainNode | null = null;
  private destinationStream: MediaStream | null = null;

  // AI ì‘ë‹µ ì˜¤ë””ì˜¤ ì¬ìƒìš© í
  private playQueue: AudioBuffer[] = [];
  private isPlaying = false;

  // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
  async initializeAudioContext(): Promise<boolean> {
    try {
      this.audioContext = new (window.AudioContext ||
        (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext)();

      if (this.audioContext.state === "suspended") {
        await this.audioContext.resume();
      }
      console.log("ğŸ›ï¸ AudioContext ready. deviceSampleRate=", this.audioContext.sampleRate);
      return true;
    } catch (err) {
      console.error("ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨:", err);
      return false;
    }
  }

  /**
   * ì…ë ¥ ìŠ¤íŠ¸ë¦¼ì„ ìº¡ì²˜í•˜ì—¬ 16k PCM16ìœ¼ë¡œ ë³€í™˜í•´ ì½œë°±ìœ¼ë¡œ ì „ë‹¬
   * - ScriptProcessorNode ì‚¬ìš© (ê°„ë‹¨/ì¦‰ì‹œ)
   * - ë‹¤ìš´ìƒ˜í”Œ: (ì˜ˆ) 48000 â†’ 16000
   */
  setupInputProcessor(inputStream: MediaStream, onAudioData: (audioBuffer: ArrayBuffer) => void): boolean {
    if (!this.audioContext) {
      console.error("ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤");
      return false;
    }

    try {
      // 1) ì…ë ¥ ì†ŒìŠ¤
      this.sourceNode = this.audioContext.createMediaStreamSource(inputStream);

      // 2) ScriptProcessorNode (deprecatedì´ê¸´ í•˜ë˜, AudioWorklet ì—†ì´ ë¹ ë¥´ê²Œ í™•ì¸ ì‹œ ê°€ì¥ ê°„ë‹¨)
      this.processorNode = this.audioContext.createScriptProcessor(BUFFER_SIZE, CHANNELS, CHANNELS);

      // 3) ì²˜ë¦¬ ë£¨í”„
      this.processorNode.onaudioprocess = (event) => {
        const inFloat = event.inputBuffer.getChannelData(0); // ì›ë³¸ float32 (ë³´í†µ 48kHz)
        const inRate = event.inputBuffer.sampleRate || this.audioContext!.sampleRate;

        // (ë””ë²„ê¹…) íŒŒí˜•ì´ ì‚´ì•„ìˆëŠ”ì§€ ê°„ë‹¨ì²´í¬
        // const peek = Math.max(...inFloat.map(v => Math.abs(v)));
        // if (peek > 0.01) console.log("ğŸ™ï¸ mic peak:", peek.toFixed(4));

        // 4) ë‹¤ìš´ìƒ˜í”Œë§ â†’ 16k float32
        const down = this.downsampleFloat32(inFloat, inRate, INPUT_TARGET_SR);

        // 5) Float32 â†’ PCM16 (ë¦¬í‹€ì—”ë””ì–¸) ë³€í™˜
        const pcm16 = this.floatToPCM16(down);

        // 6) ì½œë°±ìœ¼ë¡œ ì „ë‹¬ (OpenAIì— append)
        onAudioData(pcm16);
      };

      // 4) ë¬´ìŒ ê²½ë¡œ(ê·¸ë˜í”„ í™œì„± ìœ ì§€ + í”¼ë“œë°± ë°©ì§€)
      const silentGain = this.audioContext.createGain();
      silentGain.gain.value = 0;
      this.sourceNode.connect(this.processorNode);
      this.processorNode.connect(silentGain);
      silentGain.connect(this.audioContext.destination);

      console.log("âœ… ì…ë ¥ ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ ì„¤ì • ì™„ë£Œ (rawâ†’downsampleâ†’PCM16)");
      return true;
    } catch (err) {
      console.error("ì…ë ¥ í”„ë¡œì„¸ì„œ ì„¤ì • ì‹¤íŒ¨:", err);
      return false;
    }
  }

  /**
   * OpenAI ì‘ë‹µì„ WebRTCë¡œ ë³´ë‚´ê¸° ìœ„í•œ MediaStream ìƒì„±
   * - enqueueAIResponse()ë¡œ AudioBufferë¥¼ ì¬ìƒì‹œí‚¤ë©´ ì´ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ í˜ëŸ¬ê°‘ë‹ˆë‹¤.
   */
  createAIResponseStream(): MediaStream | null {
    if (!this.audioContext) {
      console.error("ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤");
      return null;
    }

    try {
      this.streamDestination = this.audioContext.createMediaStreamDestination();
      this.aiResponseStream = this.streamDestination.stream;
      console.log("ğŸ¯ AI ì‘ë‹µ ì „ì†¡ìš© MediaStream ìƒì„± ì™„ë£Œ");
      return this.aiResponseStream;
    } catch (err) {
      console.error("AI ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ ìƒì„± ì‹¤íŒ¨:", err);
      return null;
    }
  }

  /**
   * (ì„ íƒ) ë¡œì»¬ ì¬ìƒ/ë³¼ë¥¨ ì œì–´ê°€ í•„ìš”í•  ë•Œ í˜¸ì¶œ
   */
  createOutputProcessor(): MediaStream | null {
    if (!this.audioContext) {
      console.error("ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤");
      return null;
    }

    try {
      const destination = this.audioContext.createMediaStreamDestination();
      this.gainNode = this.audioContext.createGain();
      this.gainNode.gain.value = 1.0;
      this.gainNode.connect(destination);

      this.destinationStream = destination.stream;
      console.log("ğŸ”Š ë¡œì»¬ ì¶œë ¥ìš© MediaStream ìƒì„± ì™„ë£Œ");
      return this.destinationStream;
    } catch (err) {
      console.error("ì¶œë ¥ í”„ë¡œì„¸ì„œ ìƒì„± ì‹¤íŒ¨:", err);
      return null;
    }
  }

  /**
   * OpenAIì—ì„œ ë°›ì€ base64(PCM16 @ 24kHz ê°€ì •) ì¡°ê°ì„ íì— ë„£ê³  ìˆœì°¨ ì¬ìƒ
   * - WebRTCë¡œ ë³´ë‚¼ streamDestinationì— ì—°ê²°ë˜ì–´ ìˆì–´ì•¼ í•¨
   */
  async enqueueAIResponse(base64AudioData: string): Promise<void> {
    if (!this.audioContext || !this.streamDestination) {
      console.error("ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ë˜ëŠ” ìŠ¤íŠ¸ë¦¼ ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤");
      return;
    }

    try {
      const raw = this.base64ToArrayBuffer(base64AudioData);
      const audioBuffer = await this.pcm16ToAudioBuffer(raw, OUTPUT_SAMPLE_RATE);

      this.playQueue.push(audioBuffer);
      if (!this.isPlaying) {
        this.playNextInQueue();
      }
    } catch (err) {
      console.error("AI ì‘ë‹µ í ì¬ìƒ ì‹¤íŒ¨:", err);
    }
  }

  private playNextInQueue() {
    if (!this.audioContext || !this.streamDestination) {
      this.isPlaying = false;
      return;
    }
    if (this.playQueue.length === 0) {
      this.isPlaying = false;
      return;
    }

    this.isPlaying = true;
    const buffer = this.playQueue.shift()!;

    const sourceNode = this.audioContext.createBufferSource();
    sourceNode.buffer = buffer;

    // í•„ìš” ì‹œ ê°œë³„ ê²Œì¸(ì „ì†¡ ë ˆë²¨ ì¡°ì •)
    const g = this.audioContext.createGain();
    g.gain.value = 1.0;

    sourceNode.connect(g);
    g.connect(this.streamDestination);

    sourceNode.start(0);
    // console.log("ğŸ”Š AI ì˜¤ë””ì˜¤ ì¬ìƒ:", buffer.duration.toFixed(2), "s");

    sourceNode.onended = () => {
      this.playNextInQueue();
    };
  }

  // -------- ìœ í‹¸ë¦¬í‹°ë“¤ --------

  // ê°„ë‹¨í•œ ë‹¤ìš´ìƒ˜í”ŒëŸ¬: ì„ í˜• ë³´ê°„ ëŒ€ì‹ , ì„±ëŠ¥/ì•ˆì • ìœ„í•´ "ì§‘ê³„ ìƒ˜í”Œë§"(nearest) + ê°„ë‹¨ LPF ì—†ì´ ì‚¬ìš©
  // í•„ìš” ì‹œ í’ˆì§ˆì„ ë†’ì´ë ¤ë©´ FIR/linear interpolationì„ ì ìš© ê°€ëŠ¥
  private downsampleFloat32(input: Float32Array, inRate: number, outRate: number): Float32Array {
    if (outRate === inRate) return input.slice();
    if (outRate > inRate) {
      // ì—…ìƒ˜í”Œì´ í•„ìš”í•œ ê²½ìš°ëŠ” ì—†ìŒ(ì…ë ¥ì€ ë³´í†µ 48kì´ê³  ëª©í‘œëŠ” 16k)
      return input.slice();
    }

    const ratio = inRate / outRate;
    const newLen = Math.floor(input.length / ratio);
    const result = new Float32Array(newLen);

    let idx = 0;
    let pos = 0;
    while (idx < newLen) {
      result[idx++] = input[Math.floor(pos)] || 0;
      pos += ratio;
    }
    return result;
  }

  private floatToPCM16(float32: Float32Array): ArrayBuffer {
    const out = new ArrayBuffer(float32.length * 2);
    const view = new DataView(out);
    for (let i = 0; i < float32.length; i++) {
      const s = Math.max(-1, Math.min(1, float32[i])); // clamp
      // (ì„ íƒ) ì…ë ¥ì´ ë„ˆë¬´ ì‘ë‹¤ë©´ ì•½ê°„ì˜ ì¦í­:
      // s *= 1.5; // í•„ìš” ì‹œ ì£¼ì„ í•´ì œ
      view.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7fff, true);
    }
    return out;
  }

  private base64ToArrayBuffer(b64: string): ArrayBuffer {
    const bin = atob(b64);
    const len = bin.length;
    const buf = new ArrayBuffer(len);
    const u8 = new Uint8Array(buf);
    for (let i = 0; i < len; i++) u8[i] = bin.charCodeAt(i);
    return buf;
  }

  // PCM16 ArrayBuffer â†’ AudioBuffer (ìƒ˜í”Œë ˆì´íŠ¸ ì§€ì •)
  private async pcm16ToAudioBuffer(pcm16Data: ArrayBuffer, sampleRate: number): Promise<AudioBuffer> {
    if (!this.audioContext) throw new Error("ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤");

    const dataView = new DataView(pcm16Data);
    const frameCount = pcm16Data.byteLength / 2;
    const audioBuffer = this.audioContext.createBuffer(CHANNELS, frameCount, sampleRate);
    const chData = audioBuffer.getChannelData(0);

    for (let i = 0; i < frameCount; i++) {
      const int16 = dataView.getInt16(i * 2, true);
      chData[i] = int16 / 0x8000; // -32768~32767 â†’ -1~<1
    }
    return audioBuffer;
  }

  // (ì„ íƒ) ë¡œì»¬ ë³¼ë¥¨ ì¡°ì ˆ
  setVolume(volume: number): void {
    if (this.gainNode) {
      this.gainNode.gain.value = Math.max(0, Math.min(2, volume));
    }
  }

  // ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  cleanup(): void {
    try {
      if (this.processorNode) {
        this.processorNode.disconnect();
        this.processorNode.onaudioprocess = null;
        this.processorNode = null;
      }
      if (this.sourceNode) {
        this.sourceNode.disconnect();
        this.sourceNode = null;
      }
      if (this.gainNode) {
        this.gainNode.disconnect();
        this.gainNode = null;
      }
      if (this.streamDestination) {
        this.streamDestination.disconnect();
        this.streamDestination = null;
      }
      if (this.audioContext) {
        this.audioContext.close();
        this.audioContext = null;
      }

      this.destinationStream = null;
      this.aiResponseStream = null;
      this.playQueue = [];
      this.isPlaying = false;

      console.log("ğŸ§¹ ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ");
    } catch (e) {
      console.warn("ì •ë¦¬ ì¤‘ ê²½ê³ :", e);
    }
  }
}
